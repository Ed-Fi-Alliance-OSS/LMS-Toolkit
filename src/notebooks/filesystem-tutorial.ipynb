{
 "cells": [
  {
   "source": [
    "# Tutorial for Analyzing LMS Files\n",
    "\n",
    "## Purpose\n",
    "This notebook is designed to help analysts understand and access the files created by the Ed-Fi LMS Toolkit extractor utilities.\n",
    "\n",
    "## Pandas\n",
    "\n",
    "We'll be using [Pandas](https://pandas.pydata.org/), which is the industry standard tool for high performance data analysis in Python. If you're new to Python and Pandas and want to do some additional reading, then you might be interested in these two books by Jake VanderPlas, both available for free:\n",
    "\n",
    "* [A Whirlwind Tour of Python](https://jakevdp.github.io/WhirlwindTourOfPython/)\n",
    "* [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Getting Started\n",
    "\n",
    "This notebook was developed with Python 3.8 and might not work with earlier versions. The source code directory for this notebook contains a `poetry.lock` and `pyproject.toml` file; these are used by [Poetry](https://python-poetry.org/) to manage resource dependencies. Ideally you will install Poetry and then run `poetry install` from a command prompt to load required resources. If you would like to run without using Poetry, then you can manually load dependencies using Pip:\n",
    "\n",
    "```bash\n",
    "# Optional step if NOT using poetry\n",
    "pip install pandas\n",
    "pip install ipykernel\n",
    "pip install jupyter --user\n",
    "```\n",
    "\n",
    "It is recommended that these be installed in a virtual environment, which Poetry handles for you. Alternately, you can use equivalent commands in Anaconda.\n",
    "\n",
    "This notebook can be run from within Visual Studio Code or it can run in a browser window by executing the following command:\n",
    "\n",
    "```bash\n",
    "# With Poetry\n",
    "poetry run jupyter notebook\n",
    "\n",
    "# Without Poetry\n",
    "jupyter notebook\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Understanding the Filesystem\n",
    "\n",
    "The LMS Extractors output a number of discrete files, corresponding to concepts in the Ed-Fi LMS Unified Data Model:\n",
    "\n",
    "* Activities\n",
    "* Assignments\n",
    "* Attendance (_only with Schoology_)\n",
    "* Grades\n",
    "* Sections\n",
    "* Section Associations (aka _enrollments_)\n",
    "* Submissions\n",
    "* Users\n",
    "\n",
    "Each file contains all of the current data for the given model, so that you only need to read one file to get a complete snapshot for a single resource. But there is a catch to that: some of these concepts are section-specific, for example assignments. Rather than try to store all assignment data _for all sections_ in a single file, we create _one assignment file per section_. The same is true for activities, attendance, grades, and section associations. Furthermore, submissions are dependent on assignments, thus there is one submissions file per assignment. The file layout mirrors this heirarchy: there is a directory for each resource type, and dependent resources are nested under directories named for the given section or assignment.\n",
    "\n",
    "This convention may seem a little strange for a human, but it is very easy to navigate for the computer. Each directory may have multiple files, one for each time you run the extractor, but you only need to load the most recent file to get the current snapshot. We make that easy by using the date and time as the file name. Thus after running once, you may end up with files like this, where 12345 is the source system identifier for a unique section and 67890 is the source system identifier for a unique assignment:\n",
    "\n",
    "![Sample file layout](filesystem.svg)\n",
    "\n",
    "Note: `base_directory` is whatever directory was specified in the configuration when running the extractor utility.\n",
    "\n",
    "Presumably the extractor utility will be run on a periodic basis, for instance weekly or daily. In that case each directory will have multiple files. Since the filenames have the date and time embedded in them, sorting on the file names will make it easy to pick up only the most recent file, regardless of whether or not some other process has modified the file and thus altered the operating system date on the file.\n",
    "\n",
    "## Helper Functions\n",
    "\n",
    "### Filesystem Helpers\n",
    "\n",
    "Below you will find a set of functions to help you navigate this filesystem.\n",
    "\n",
    "LANGUAGE USE NOTE: in these examples we use Python's optional [type hint system](https://docs.python.org/3.8/library/typing.html) to help us all recognize what data types are being passed into functions and returned by them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def _get_newest_file(directory: str) -> str:\n",
    "    files = [(f.path, f.name) for f in os.scandir(directory) if f.name.endswith(\".csv\")]\n",
    "    files = sorted(files, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return files[0][0]\n",
    "\n",
    "def _get_file_for_section(base_directory, section_id, file_type) -> str:\n",
    "    return _get_newest_file(os.path.join(base_directory, f\"section={section_id}\", file_type))\n",
    "\n",
    "def get_users_file(base_directory) -> str:\n",
    "    return _get_newest_file(os.path.join(base_directory, \"users\"))\n",
    "\n",
    "def get_sections_file(base_directory):\n",
    "    return _get_newest_file(os.path.join(base_directory, \"sections\"))\n",
    "\n",
    "def get_section_associations_file(base_directory, section_id):\n",
    "    return _get_file_for_section(base_directory, section_id, \"section-associations\")\n",
    "\n",
    "def get_activities_file(base_directory, section_id):\n",
    "    return _get_file_for_section(base_directory, section_id, \"activities\")\n",
    "\n",
    "def get_assignments_file(base_directory, section_id):\n",
    "    return _get_file_for_section(base_directory, section_id, \"assignments\")\n",
    "\n",
    "def get_grades_file(base_directory, section_id):\n",
    "    return _get_file_for_section(base_directory, section_id, \"grades\")"
   ]
  },
  {
   "source": [
    "#### Function Validation\n",
    "\n",
    "The code below validates the output from these functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All good\n"
     ]
    }
   ],
   "source": [
    "sample_dir = os.path.join(\"..\", \"..\", \"docs\", \"sample-out\")\n",
    "\n",
    "# Users\n",
    "expected_file = os.path.join(sample_dir, \"users\", \"2020-09-18-15-05-01.csv\")\n",
    "actual_file = get_users_file(sample_dir)\n",
    "assert expected_file == actual_file, f\"Users > Expected: {expected_file}, Actual: {actual_file}\"\n",
    "\n",
    "# Sections\n",
    "expected_file = os.path.join(sample_dir, \"sections\", \"2020-09-17-15-04-23.csv\")\n",
    "actual_file = get_sections_file(sample_dir)\n",
    "assert expected_file == actual_file, f\"Sections > Expected: {expected_file}, Actual: {actual_file}\"\n",
    "\n",
    "# Activities for section 2385758954\n",
    "expected_file = os.path.join(sample_dir, \"section=2385758954\", \"activities\", \"2020-09-21-11-08-34.csv\")\n",
    "actual_file = get_activities_file(sample_dir, 2385758954)\n",
    "assert expected_file == actual_file, f\"Activities > Expected: {expected_file}, Actual: {actual_file}\"\n",
    "\n",
    "# Assignments for section 123456780\n",
    "expected_file = os.path.join(sample_dir, \"section=123456780\", \"assignments\", \"2020-09-18-15-04-24.csv\")\n",
    "actual_file = get_assignments_file(sample_dir, 123456780)\n",
    "assert expected_file == actual_file, f\"Assignments > Expected: {expected_file}, Actual: {actual_file}\"\n",
    "\n",
    "# Grades for section 123456780\n",
    "expected_file = os.path.join(sample_dir, \"section=123456780\", \"grades\", \"2020-09-18-15-04-24.csv\")\n",
    "actual_file = get_grades_file(sample_dir, 123456780)\n",
    "assert expected_file == actual_file, f\"Grades > Expected: {expected_file}, Actual: {actual_file}\"\n",
    "\n",
    "# Section Associations for section 123456789\n",
    "expected_file = os.path.join(sample_dir, \"section=123456789\", \"section-associations\", \"2020-09-18-15-04-24.csv\")\n",
    "actual_file = get_section_associations_file(sample_dir, 123456789)\n",
    "assert expected_file == actual_file, f\"Section Associations > Expected: {expected_file}, Actual: {actual_file}\"\n",
    "\n",
    "\n",
    "print(\"All good\")"
   ]
  },
  {
   "source": [
    "### Loading Files into DataFrames\n",
    "\n",
    "Next, let's create a few functions that leverage the filesystem helpers to read files into Pandas DataFrames."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Aliasing as `pd` is a common practice in the industry\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('.venv')",
   "display_name": "Python 3.8.5 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "345aa749e0416ef4341931074d5302fa58a65d7e36b033cb1301f4b45f255c63"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}